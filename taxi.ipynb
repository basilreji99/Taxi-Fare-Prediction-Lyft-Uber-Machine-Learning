{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c76c719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('rideshare_kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2be6a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 693071 entries, 0 to 693070\n",
      "Data columns (total 57 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   id                           693071 non-null  object \n",
      " 1   timestamp                    693071 non-null  float64\n",
      " 2   hour                         693071 non-null  int64  \n",
      " 3   day                          693071 non-null  int64  \n",
      " 4   month                        693071 non-null  int64  \n",
      " 5   datetime                     693071 non-null  object \n",
      " 6   timezone                     693071 non-null  object \n",
      " 7   source                       693071 non-null  object \n",
      " 8   destination                  693071 non-null  object \n",
      " 9   cab_type                     693071 non-null  object \n",
      " 10  product_id                   693071 non-null  object \n",
      " 11  name                         693071 non-null  object \n",
      " 12  price                        637976 non-null  float64\n",
      " 13  distance                     693071 non-null  float64\n",
      " 14  surge_multiplier             693071 non-null  float64\n",
      " 15  latitude                     693071 non-null  float64\n",
      " 16  longitude                    693071 non-null  float64\n",
      " 17  temperature                  693071 non-null  float64\n",
      " 18  apparentTemperature          693071 non-null  float64\n",
      " 19  short_summary                693071 non-null  object \n",
      " 20  long_summary                 693071 non-null  object \n",
      " 21  precipIntensity              693071 non-null  float64\n",
      " 22  precipProbability            693071 non-null  float64\n",
      " 23  humidity                     693071 non-null  float64\n",
      " 24  windSpeed                    693071 non-null  float64\n",
      " 25  windGust                     693071 non-null  float64\n",
      " 26  windGustTime                 693071 non-null  int64  \n",
      " 27  visibility                   693071 non-null  float64\n",
      " 28  temperatureHigh              693071 non-null  float64\n",
      " 29  temperatureHighTime          693071 non-null  int64  \n",
      " 30  temperatureLow               693071 non-null  float64\n",
      " 31  temperatureLowTime           693071 non-null  int64  \n",
      " 32  apparentTemperatureHigh      693071 non-null  float64\n",
      " 33  apparentTemperatureHighTime  693071 non-null  int64  \n",
      " 34  apparentTemperatureLow       693071 non-null  float64\n",
      " 35  apparentTemperatureLowTime   693071 non-null  int64  \n",
      " 36  icon                         693071 non-null  object \n",
      " 37  dewPoint                     693071 non-null  float64\n",
      " 38  pressure                     693071 non-null  float64\n",
      " 39  windBearing                  693071 non-null  int64  \n",
      " 40  cloudCover                   693071 non-null  float64\n",
      " 41  uvIndex                      693071 non-null  int64  \n",
      " 42  visibility.1                 693071 non-null  float64\n",
      " 43  ozone                        693071 non-null  float64\n",
      " 44  sunriseTime                  693071 non-null  int64  \n",
      " 45  sunsetTime                   693071 non-null  int64  \n",
      " 46  moonPhase                    693071 non-null  float64\n",
      " 47  precipIntensityMax           693071 non-null  float64\n",
      " 48  uvIndexTime                  693071 non-null  int64  \n",
      " 49  temperatureMin               693071 non-null  float64\n",
      " 50  temperatureMinTime           693071 non-null  int64  \n",
      " 51  temperatureMax               693071 non-null  float64\n",
      " 52  temperatureMaxTime           693071 non-null  int64  \n",
      " 53  apparentTemperatureMin       693071 non-null  float64\n",
      " 54  apparentTemperatureMinTime   693071 non-null  int64  \n",
      " 55  apparentTemperatureMax       693071 non-null  float64\n",
      " 56  apparentTemperatureMaxTime   693071 non-null  int64  \n",
      "dtypes: float64(29), int64(17), object(11)\n",
      "memory usage: 301.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba2f4c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Haymarket Square' 'Back Bay' 'North End' 'North Station' 'Beacon Hill'\n",
      " 'Boston University' 'Fenway' 'South Station' 'Theatre District'\n",
      " 'West End' 'Financial District' 'Northeastern University']\n",
      "['North Station' 'Northeastern University' 'West End' 'Haymarket Square'\n",
      " 'South Station' 'Fenway' 'Theatre District' 'Beacon Hill' 'Back Bay'\n",
      " 'North End' 'Financial District' 'Boston University']\n"
     ]
    }
   ],
   "source": [
    "unique_sources = df['source'].unique()\n",
    "unique_destinations = df['destination'].unique()\n",
    "print(unique_sources)\n",
    "print(unique_destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78077b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e34cb9a-05c4-4d8a-8f55-8c8afe1bfbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'windGust', 'windGustTime', 'temperatureHigh', 'temperatureHighTime', \n",
    "    'temperatureLow', 'temperatureLowTime', 'apparentTemperatureHigh', 'apparentTemperatureHighTime',\n",
    "    'apparentTemperatureLow', 'apparentTemperatureLowTime', 'dewPoint', 'pressure',\n",
    "    'windBearing', 'cloudCover', 'uvIndex', 'ozone', 'sunriseTime', 'sunsetTime',\n",
    "    'moonPhase', 'precipIntensityMax', 'uvIndexTime', 'temperatureMin', 'temperatureMinTime',\n",
    "    'temperatureMax', 'temperatureMaxTime', 'apparentTemperatureMin', 'apparentTemperatureMinTime',\n",
    "    'apparentTemperatureMax', 'apparentTemperatureMaxTime', 'visibility.1'\n",
    "]\n",
    "df = df.drop(columns_to_drop, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f4da9a6-a64d-4c21-83c1-dbbb2a7c39a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07687ec5-dfe7-41ce-ad79-17f769f00cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8b9c2ff-fe55-432c-9ab9-2c0e0538f346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['datetime', 'timezone', 'timestamp','icon','product_id','latitude','longitude'], axis='columns')\n",
    "print(\"Number of duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17cde613-23de-49da-91bb-dd7e53877a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "hour                       0\n",
       "day                        0\n",
       "month                      0\n",
       "source                     0\n",
       "destination                0\n",
       "cab_type                   0\n",
       "name                       0\n",
       "price                  55095\n",
       "distance                   0\n",
       "surge_multiplier           0\n",
       "temperature                0\n",
       "apparentTemperature        0\n",
       "short_summary              0\n",
       "long_summary               0\n",
       "precipIntensity            0\n",
       "precipProbability          0\n",
       "humidity                   0\n",
       "windSpeed                  0\n",
       "visibility                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67c8040d-f8ba-4e62-bf26-d4de59a15319",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2473756d-67d2-43ac-8456-e4c85fcb9ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['destination','source'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e3cc5f7-97d1-4505-8b81-ae1836d06dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "094b4520-c3c6-4b7b-8830-afe9c6317393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6516bd8-125d-40ab-93ec-3b96c5fc1679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 637976 entries, 0 to 693070\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   id                   637976 non-null  object \n",
      " 1   hour                 637976 non-null  int64  \n",
      " 2   day                  637976 non-null  int64  \n",
      " 3   month                637976 non-null  int64  \n",
      " 4   cab_type             637976 non-null  object \n",
      " 5   name                 637976 non-null  object \n",
      " 6   price                637976 non-null  float64\n",
      " 7   distance             637976 non-null  float64\n",
      " 8   surge_multiplier     637976 non-null  float64\n",
      " 9   temperature          637976 non-null  float64\n",
      " 10  apparentTemperature  637976 non-null  float64\n",
      " 11  short_summary        637976 non-null  object \n",
      " 12  long_summary         637976 non-null  object \n",
      " 13  precipIntensity      637976 non-null  float64\n",
      " 14  precipProbability    637976 non-null  float64\n",
      " 15  humidity             637976 non-null  float64\n",
      " 16  windSpeed            637976 non-null  float64\n",
      " 17  visibility           637976 non-null  float64\n",
      "dtypes: float64(10), int64(3), object(5)\n",
      "memory usage: 92.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a5f9b61-a79a-461b-a77a-3d0bb46500ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 637976 entries, 0 to 637975\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   id                   637976 non-null  object \n",
      " 1   hour                 637976 non-null  int64  \n",
      " 2   day                  637976 non-null  int64  \n",
      " 3   month                637976 non-null  int64  \n",
      " 4   cab_type             637976 non-null  object \n",
      " 5   price                637976 non-null  float64\n",
      " 6   distance             637976 non-null  float64\n",
      " 7   surge_multiplier     637976 non-null  float64\n",
      " 8   temperature          637976 non-null  float64\n",
      " 9   apparentTemperature  637976 non-null  float64\n",
      " 10  precipIntensity      637976 non-null  float64\n",
      " 11  precipProbability    637976 non-null  float64\n",
      " 12  humidity             637976 non-null  float64\n",
      " 13  windSpeed            637976 non-null  float64\n",
      " 14  visibility           637976 non-null  float64\n",
      " 15  long_summary         637976 non-null  float64\n",
      " 16  short_summary        637976 non-null  float64\n",
      " 17  name                 637976 non-null  float64\n",
      "dtypes: float64(13), int64(3), object(2)\n",
      "memory usage: 87.6+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "categorical_cols = ['long_summary', 'short_summary', 'name']\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "encoded_data = ordinal_encoder.fit_transform(df[categorical_cols])\n",
    "\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=ordinal_encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "df.drop(columns=categorical_cols, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "encoded_df.reset_index(drop=True, inplace=True)\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b368d17a-99af-45a6-801c-567944bec0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9117dd59-34f5-4913-8624-c7e60342491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# categorical_cols = ['cab_type']\n",
    "# one_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# encoded_data = one_encoder.fit_transform(df[categorical_cols])\n",
    "\n",
    "# encoded_df = pd.DataFrame(encoded_data, columns=one_encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# df.drop(columns=categorical_cols, inplace=True)\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# encoded_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af0dc1d2-0d48-4b7d-a77a-3746cf28a6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 637976 entries, 0 to 637975\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   id                   637976 non-null  object \n",
      " 1   hour                 637976 non-null  int64  \n",
      " 2   day                  637976 non-null  int64  \n",
      " 3   month                637976 non-null  int64  \n",
      " 4   price                637976 non-null  float64\n",
      " 5   distance             637976 non-null  float64\n",
      " 6   surge_multiplier     637976 non-null  float64\n",
      " 7   temperature          637976 non-null  float64\n",
      " 8   apparentTemperature  637976 non-null  float64\n",
      " 9   precipIntensity      637976 non-null  float64\n",
      " 10  precipProbability    637976 non-null  float64\n",
      " 11  humidity             637976 non-null  float64\n",
      " 12  windSpeed            637976 non-null  float64\n",
      " 13  visibility           637976 non-null  float64\n",
      " 14  long_summary         637976 non-null  float64\n",
      " 15  short_summary        637976 non-null  float64\n",
      " 16  name                 637976 non-null  float64\n",
      " 17  cab_type_Lyft        637976 non-null  float64\n",
      " 18  cab_type_Uber        637976 non-null  float64\n",
      "dtypes: float64(15), int64(3), object(1)\n",
      "memory usage: 92.5+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming df is your DataFrame and contains the 'cab_type' column\n",
    "categorical_cols = ['cab_type']\n",
    "\n",
    "# Initialize OneHotEncoder with sparse_output=False\n",
    "one_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit and transform the data\n",
    "encoded_data = one_encoder.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Create a DataFrame from the encoded data\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=one_encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Drop the original categorical columns from the original DataFrame\n",
    "df.drop(columns=categorical_cols, inplace=True)\n",
    "\n",
    "# Reset index for both DataFrames\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "encoded_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate the original DataFrame with the encoded DataFrame\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "# Display information about the DataFrame\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9814e084-daaa-430b-8bd2-01b47d9d91e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd8ac89d-ca2c-4f36-bf20-85f3efa294af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c40bd22-4d9d-4c14-b715-bb2271911b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Select features and target\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9169f4d-8f90-4d38-8692-9dded18ad885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 5.168819725468217\n",
      "Mean Squared Error: 42.283224197398376\n",
      "Root Mean Squared Error: 6.502555205255729\n",
      "R^2 Score: 0.5133387234776488\n"
     ]
    }
   ],
   "source": [
    "# Initialize Linear Regression Model\n",
    "import numpy as np\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicting\n",
    "y_pred = model.predict(X_train_scaled)\n",
    "\n",
    "# Metrics\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1e9dd54-e619-4455-ac01-28c99c90e6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 5.159272787252324\n",
      "Mean Squared Error: 42.13113010709403\n",
      "Root Mean Squared Error: 6.4908497214998\n",
      "R^2 Score: 0.5167363399782146\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc98820f-68cd-48aa-a801-323ff1400634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression Metrics\n",
      "Mean Absolute Error: 3.616448778097513\n",
      "Mean Squared Error: 24.944042250420836\n",
      "Root Mean Squared Error: 4.994401090263059\n",
      "R^2 Score: 0.7129050664030445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=3)  # You can adjust the degree based on your needs\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_poly_scaled = scaler.fit_transform(X_train_poly)\n",
    "X_test_poly_scaled = scaler.transform(X_test_poly)\n",
    "\n",
    "# Initialize and train the linear regression model on the polynomial features\n",
    "model_poly = LinearRegression()\n",
    "model_poly.fit(X_train_poly_scaled, y_train)\n",
    "\n",
    "# Predicting\n",
    "y_pred_poly = model_poly.predict(X_train_poly_scaled)\n",
    "\n",
    "# Calculate new metrics\n",
    "mae_poly = mean_absolute_error(y_train, y_pred_poly)\n",
    "mse_poly = mean_squared_error(y_train, y_pred_poly)\n",
    "rmse_poly = np.sqrt(mse_poly)\n",
    "r2_poly = r2_score(y_train, y_pred_poly)\n",
    "\n",
    "print(\"Polynomial Regression Metrics\")\n",
    "print(\"Mean Absolute Error:\", mae_poly)\n",
    "print(\"Mean Squared Error:\", mse_poly)\n",
    "print(\"Root Mean Squared Error:\", rmse_poly)\n",
    "print(\"R^2 Score:\", r2_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "710052c0-d787-4c7d-ae7d-612a7f49d270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression Metrics\n",
      "Mean Absolute Error: 3.6068072720765265\n",
      "Mean Squared Error: 24.7998079504916\n",
      "Root Mean Squared Error: 4.9799405569235065\n",
      "R^2 Score: 0.7155346669427711\n"
     ]
    }
   ],
   "source": [
    "# Predicting\n",
    "y_pred_poly = model_poly.predict(X_test_poly_scaled)\n",
    "\n",
    "# Calculate new metrics\n",
    "mae_poly = mean_absolute_error(y_test, y_pred_poly)\n",
    "mse_poly = mean_squared_error(y_test, y_pred_poly)\n",
    "rmse_poly = np.sqrt(mse_poly)\n",
    "r2_poly = r2_score(y_test, y_pred_poly)\n",
    "\n",
    "print(\"Polynomial Regression Metrics\")\n",
    "print(\"Mean Absolute Error:\", mae_poly)\n",
    "print(\"Mean Squared Error:\", mse_poly)\n",
    "print(\"Root Mean Squared Error:\", rmse_poly)\n",
    "print(\"R^2 Score:\", r2_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c98a1c42-fe72-4115-bd16-586918df51a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Metrics\n",
      "Mean Absolute Error: 3.6151073658845467\n",
      "Mean Squared Error: 24.941520160725563\n",
      "Root Mean Squared Error: 4.994148592175203\n",
      "R^2 Score: 0.7129340945439657\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "# Initialize Ridge Regression Model\n",
    "# Alpha is a hyperparameter for regularization strength. Adjust as necessary.\n",
    "ridge_model = Ridge(alpha=2.0)\n",
    "\n",
    "# Train the model\n",
    "ridge_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Predicting\n",
    "y_pred = ridge_model.predict(X_train_poly)\n",
    "\n",
    "# Metrics\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Ridge Regression Metrics\")\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd650c8d-5755-4def-b387-566f6a7da0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Metrics\n",
      "Mean Absolute Error: 3.604900209238024\n",
      "Mean Squared Error: 24.78934902173963\n",
      "Root Mean Squared Error: 4.978890340401125\n",
      "R^2 Score: 0.7156546357206258\n"
     ]
    }
   ],
   "source": [
    "y_pred = ridge_model.predict(X_test_poly)\n",
    "\n",
    "# Metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Ridge Regression Metrics\")\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9589e4e6-e1d9-4359-bd03-9844a2f5e757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression Training Metrics\n",
      "Train Mean Absolute Error: 0.4094475962811566\n",
      "Train Mean Squared Error: 0.8721610245331504\n",
      "Train Root Mean Squared Error: 0.9338956175789404\n",
      "Train R^2 Score: 0.9899618109643006\n",
      "\n",
      "Decision Tree Regression Testing Metrics\n",
      "Test Mean Absolute Error: 1.4364660938414229\n",
      "Test Mean Squared Error: 5.518209394665103\n",
      "Test Root Mean Squared Error: 2.3490869278647613\n",
      "Test R^2 Score: 0.9367035713959301\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Decision Tree Regressor\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting\n",
    "y_train_pred_dt = dt_model.predict(X_train)\n",
    "y_test_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Metrics for training data\n",
    "train_mae_dt = mean_absolute_error(y_train, y_train_pred_dt)\n",
    "train_mse_dt = mean_squared_error(y_train, y_train_pred_dt)\n",
    "train_rmse_dt = np.sqrt(train_mse_dt)\n",
    "train_r2_dt = r2_score(y_train, y_train_pred_dt)\n",
    "\n",
    "# Metrics for testing data\n",
    "test_mae_dt = mean_absolute_error(y_test, y_test_pred_dt)\n",
    "test_mse_dt = mean_squared_error(y_test, y_test_pred_dt)\n",
    "test_rmse_dt = np.sqrt(test_mse_dt)\n",
    "test_r2_dt = r2_score(y_test, y_test_pred_dt)\n",
    "\n",
    "# Print performance metrics for both train and test sets\n",
    "print(\"Decision Tree Regression Training Metrics\")\n",
    "print(\"Train Mean Absolute Error:\", train_mae_dt)\n",
    "print(\"Train Mean Squared Error:\", train_mse_dt)\n",
    "print(\"Train Root Mean Squared Error:\", train_rmse_dt)\n",
    "print(\"Train R^2 Score:\", train_r2_dt)\n",
    "\n",
    "print(\"\\nDecision Tree Regression Testing Metrics\")\n",
    "print(\"Test Mean Absolute Error:\", test_mae_dt)\n",
    "print(\"Test Mean Squared Error:\", test_mse_dt)\n",
    "print(\"Test Root Mean Squared Error:\", test_rmse_dt)\n",
    "print(\"Test R^2 Score:\", test_r2_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "198b6c33-e465-44d6-bdea-665799db6509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max Depth</th>\n",
       "      <th>Training Error</th>\n",
       "      <th>Test Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>1.519288</td>\n",
       "      <td>4.700877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>1.396170</td>\n",
       "      <td>4.882170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>1.288710</td>\n",
       "      <td>4.981964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1.197388</td>\n",
       "      <td>5.123359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>1.121435</td>\n",
       "      <td>5.187625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>1.059813</td>\n",
       "      <td>5.262240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>1.010693</td>\n",
       "      <td>5.329589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28</td>\n",
       "      <td>0.972025</td>\n",
       "      <td>5.381027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29</td>\n",
       "      <td>0.942726</td>\n",
       "      <td>5.410010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30</td>\n",
       "      <td>0.922009</td>\n",
       "      <td>5.428563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31</td>\n",
       "      <td>0.906175</td>\n",
       "      <td>5.432257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>0.894371</td>\n",
       "      <td>5.472665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>33</td>\n",
       "      <td>0.887197</td>\n",
       "      <td>5.482235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>34</td>\n",
       "      <td>0.881453</td>\n",
       "      <td>5.500930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35</td>\n",
       "      <td>0.878539</td>\n",
       "      <td>5.492792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36</td>\n",
       "      <td>0.876301</td>\n",
       "      <td>5.496964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>37</td>\n",
       "      <td>0.874657</td>\n",
       "      <td>5.511015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>38</td>\n",
       "      <td>0.873581</td>\n",
       "      <td>5.512373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>39</td>\n",
       "      <td>0.873053</td>\n",
       "      <td>5.512275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Max Depth  Training Error  Test Error\n",
       "0          21        1.519288    4.700877\n",
       "1          22        1.396170    4.882170\n",
       "2          23        1.288710    4.981964\n",
       "3          24        1.197388    5.123359\n",
       "4          25        1.121435    5.187625\n",
       "5          26        1.059813    5.262240\n",
       "6          27        1.010693    5.329589\n",
       "7          28        0.972025    5.381027\n",
       "8          29        0.942726    5.410010\n",
       "9          30        0.922009    5.428563\n",
       "10         31        0.906175    5.432257\n",
       "11         32        0.894371    5.472665\n",
       "12         33        0.887197    5.482235\n",
       "13         34        0.881453    5.500930\n",
       "14         35        0.878539    5.492792\n",
       "15         36        0.876301    5.496964\n",
       "16         37        0.874657    5.511015\n",
       "17         38        0.873581    5.512373\n",
       "18         39        0.873053    5.512275"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def max_depth_error(md):\n",
    "    # Initialize the DecisionTreeRegressor with varying max_depth\n",
    "    model = DecisionTreeRegressor(max_depth=md, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate errors as 1 minus the R^2 score; more commonly though, you'd use the actual error metric directly\n",
    "    train_error = mean_squared_error(y_train, model.predict(X_train))\n",
    "    test_error = mean_squared_error(y_test, model.predict(X_test))\n",
    "    \n",
    "    return {'Max Depth': md, 'Training Error': train_error, 'Test Error': test_error}\n",
    "\n",
    "# Generate errors for a range of depth values\n",
    "errors_df = pd.DataFrame([max_depth_error(md) for md in range(21, 40)])\n",
    "\n",
    "errors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "989abb13-5dd4-4591-955d-2dab557e3bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Training Metrics\n",
      "Train Mean Absolute Error: 0.6557961170312491\n",
      "Train Mean Squared Error: 1.1459420193902927\n",
      "Train Root Mean Squared Error: 1.0704868142066453\n",
      "Train R^2 Score: 0.9868107123673082\n",
      "\n",
      "Random Forest Regression Testing Metrics\n",
      "Test Mean Absolute Error: 1.2676680718760538\n",
      "Test Mean Squared Error: 3.7615600680776833\n",
      "Test Root Mean Squared Error: 1.9394741730885934\n",
      "Test R^2 Score: 0.9568531562939269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "# Initialize Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)  # n_estimators can be tuned\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting\n",
    "y_train_pred_rf = rf_model.predict(X_train)\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Metrics for training data\n",
    "train_mae_rf = mean_absolute_error(y_train, y_train_pred_rf)\n",
    "train_mse_rf = mean_squared_error(y_train, y_train_pred_rf)\n",
    "train_rmse_rf = np.sqrt(train_mse_rf)\n",
    "train_r2_rf = r2_score(y_train, y_train_pred_rf)\n",
    "\n",
    "# Metrics for testing data\n",
    "test_mae_rf = mean_absolute_error(y_test, y_test_pred_rf)\n",
    "test_mse_rf = mean_squared_error(y_test, y_test_pred_rf)\n",
    "test_rmse_rf = np.sqrt(test_mse_rf)\n",
    "test_r2_rf = r2_score(y_test, y_test_pred_rf)\n",
    "\n",
    "# Print performance metrics for both train and test sets\n",
    "print(\"Random Forest Regression Training Metrics\")\n",
    "print(\"Train Mean Absolute Error:\", train_mae_rf)\n",
    "print(\"Train Mean Squared Error:\", train_mse_rf)\n",
    "print(\"Train Root Mean Squared Error:\", train_rmse_rf)\n",
    "print(\"Train R^2 Score:\", train_r2_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Regression Testing Metrics\")\n",
    "print(\"Test Mean Absolute Error:\", test_mae_rf)\n",
    "print(\"Test Mean Squared Error:\", test_mse_rf)\n",
    "print(\"Test Root Mean Squared Error:\", test_rmse_rf)\n",
    "print(\"Test R^2 Score:\", test_r2_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd4be76e-2a85-49cb-967f-2f6318cd7ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Training Metrics\n",
      "Train Mean Absolute Error: 0.6557961170312491\n",
      "Train Mean Squared Error: 1.1459420193902927\n",
      "Train Root Mean Squared Error: 1.0704868142066453\n",
      "Train R^2 Score: 0.9868107123673082\n",
      "\n",
      "Random Forest Regression Testing Metrics\n",
      "Test Mean Absolute Error: 1.2676680718760538\n",
      "Test Mean Squared Error: 3.7615600680776833\n",
      "Test Root Mean Squared Error: 1.9394741730885934\n",
      "Test R^2 Score: 0.9568531562939269\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Metrics for training data\n",
    "train_mae_rf = mean_absolute_error(y_train, y_train_pred_rf)\n",
    "train_mse_rf = mean_squared_error(y_train, y_train_pred_rf)\n",
    "train_rmse_rf = np.sqrt(train_mse_rf)\n",
    "train_r2_rf = r2_score(y_train, y_train_pred_rf)\n",
    "\n",
    "# Metrics for testing data\n",
    "test_mae_rf = mean_absolute_error(y_test, y_test_pred_rf)\n",
    "test_mse_rf = mean_squared_error(y_test, y_test_pred_rf)\n",
    "test_rmse_rf = np.sqrt(test_mse_rf)\n",
    "test_r2_rf = r2_score(y_test, y_test_pred_rf)\n",
    "\n",
    "# Print performance metrics for both train and test sets\n",
    "print(\"Random Forest Regression Training Metrics\")\n",
    "print(\"Train Mean Absolute Error:\", train_mae_rf)\n",
    "print(\"Train Mean Squared Error:\", train_mse_rf)\n",
    "print(\"Train Root Mean Squared Error:\", train_rmse_rf)\n",
    "print(\"Train R^2 Score:\", train_r2_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Regression Testing Metrics\")\n",
    "print(\"Test Mean Absolute Error:\", test_mae_rf)\n",
    "print(\"Test Mean Squared Error:\", test_mse_rf)\n",
    "print(\"Test Root Mean Squared Error:\", test_rmse_rf)\n",
    "print(\"Test R^2 Score:\", test_r2_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a948cdc-d3c5-475b-b325-6f644ed136a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: [17.5665]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basil\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a list of random values for each feature\n",
    "# Ensure these values are reasonable based on the expected ranges and types of the features\n",
    "feature_values = [\n",
    "    14,  # hour\n",
    "    2,  # day\n",
    "    4,   # month\n",
    "    3,  # distance\n",
    "    1.0,  # surge_multiplier\n",
    "    53.0,  # temperature\n",
    "    55.0,  # apparentTemperature\n",
    "    0,  # precipIntensity\n",
    "    0,   # precipProbability\n",
    "    0.21,   # humidity\n",
    "    12.0,  # windSpeed\n",
    "    10.0,   # visibility\n",
    "    4,   # long_summary (assuming numerical encoding or placeholder)\n",
    "    0,   # short_summary (assuming numerical encoding or placeholder)\n",
    "    6,   # name (assuming numerical encoding or placeholder)\n",
    "    1,    # cab_type_Lyft (binary)\n",
    "    0     # cab_type_Uber (binary)\n",
    "]\n",
    "\n",
    "# Convert the list to a numpy array and reshape it to be 2D\n",
    "input_features = np.array(feature_values).reshape(1, -1)\n",
    "\n",
    "# Assuming rf_model is your trained RandomForestRegressor\n",
    "predicted_value = rf_model.predict(input_features)\n",
    "\n",
    "print(\"Predicted Value:\", predicted_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20450ccd-a49d-43ce-9d13-fea97084f0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one_encoder.joblib']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "# Assuming 'ordinal_encoder' is your fitted OrdinalEncoder\n",
    "joblib.dump(ordinal_encoder, 'ordinal_encoder.joblib')\n",
    "\n",
    "# Assuming 'one_hot_encoder' is your fitted OneHotEncoder\n",
    "joblib.dump(one_encoder, 'one_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6bd326b0-c717-4d2b-8a86-583bc7cd94fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Training Metrics\n",
      "Train Mean Absolute Error: 0.6557961170312491\n",
      "Train Mean Squared Error: 1.1459420193902927\n",
      "Train Root Mean Squared Error: 1.0704868142066453\n",
      "Train R^2 Score: 0.9868107123673082\n",
      "\n",
      "Random Forest Regression Testing Metrics\n",
      "Test Mean Absolute Error: 1.2676680718760538\n",
      "Test Mean Squared Error: 3.7615600680776833\n",
      "Test Root Mean Squared Error: 1.9394741730885934\n",
      "Test R^2 Score: 0.9568531562939269\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "train_mae_rf = mean_absolute_error(y_train, y_train_pred_rf)\n",
    "train_mse_rf = mean_squared_error(y_train, y_train_pred_rf)\n",
    "train_rmse_rf = np.sqrt(train_mse_rf)\n",
    "train_r2_rf = r2_score(y_train, y_train_pred_rf)\n",
    "\n",
    "# Metrics for testing data\n",
    "test_mae_rf = mean_absolute_error(y_test, y_test_pred_rf)\n",
    "test_mse_rf = mean_squared_error(y_test, y_test_pred_rf)\n",
    "test_rmse_rf = np.sqrt(test_mse_rf)\n",
    "test_r2_rf = r2_score(y_test, y_test_pred_rf)\n",
    "\n",
    "# Print performance metrics for both train and test sets\n",
    "print(\"Random Forest Regression Training Metrics\")\n",
    "print(\"Train Mean Absolute Error:\", train_mae_rf)\n",
    "print(\"Train Mean Squared Error:\", train_mse_rf)\n",
    "print(\"Train Root Mean Squared Error:\", train_rmse_rf)\n",
    "print(\"Train R^2 Score:\", train_r2_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Regression Testing Metrics\")\n",
    "print(\"Test Mean Absolute Error:\", test_mae_rf)\n",
    "print(\"Test Mean Squared Error:\", test_mse_rf)\n",
    "print(\"Test Root Mean Squared Error:\", test_rmse_rf)\n",
    "print(\"Test R^2 Score:\", test_r2_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d8d847a-0e24-4ccd-85da-240bb90f5ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model Parameters  Training Error  \\\n",
      "0  {'n_estimators': 50, 'max_depth': 10, 'random_...        2.978254   \n",
      "1  {'n_estimators': 100, 'max_depth': 15, 'random...        2.344302   \n",
      "2  {'n_estimators': 150, 'max_depth': 20, 'random...        1.812101   \n",
      "\n",
      "   Testing Error  \n",
      "0       3.058017  \n",
      "1       3.099558  \n",
      "2       3.280592  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming df is already loaded and cleaned\n",
    "# X = df.drop('price', axis=1)\n",
    "# y = df['price']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define different sets of parameters for RandomForestRegressor\n",
    "params = [\n",
    "    {'n_estimators': 50, 'max_depth': 10, 'random_state': 42},\n",
    "    {'n_estimators': 100, 'max_depth': 15, 'random_state': 42, 'min_samples_split': 4},\n",
    "    {'n_estimators': 150, 'max_depth': 20, 'random_state': 42, 'min_samples_leaf': 2}\n",
    "]\n",
    "\n",
    "# Train a RandomForest model for each set of parameters\n",
    "results = []\n",
    "for param in params:\n",
    "    model = RandomForestRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "    train_error = mean_squared_error(y_train, train_preds)\n",
    "    test_error = mean_squared_error(y_test, test_preds)\n",
    "    results.append({\n",
    "        'Model Parameters': param,\n",
    "        'Training Error': train_error,\n",
    "        'Testing Error': test_error\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4be87cb6-4299-42bc-928f-616cffb71195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regression Training Metrics\n",
      "Training MSE: 3.1926936916141813\n",
      "Training R^2: 0.9632535026124754\n",
      "\n",
      "XGBoost Regression Validation Metrics\n",
      "Validation MSE: 3.165329372772213\n",
      "Validation R^2: 0.9636921997114245\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Assuming df is already loaded and cleaned\n",
    "# X = df.drop('price', axis=1)\n",
    "# y = df['price']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,  # number of trees\n",
    "    learning_rate=0.1,  # step size shrinkage used to prevent overfitting\n",
    "    max_depth=5,  # depth of trees\n",
    "    subsample=0.8,  # percentage of samples used per tree\n",
    "    colsample_bytree=0.8,  # percentage of features used per tree\n",
    "    objective='reg:squarederror',  # loss function\n",
    "    random_state=42  # seed\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "y_val_pred = xgb_model.predict(X_val)\n",
    "\n",
    "# Metrics for training data\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Metrics for validation data\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Print performance metrics for both train and validation sets\n",
    "print(\"XGBoost Regression Training Metrics\")\n",
    "print(\"Training MSE:\", train_mse)\n",
    "print(\"Training R^2:\", train_r2)\n",
    "\n",
    "print(\"\\nXGBoost Regression Validation Metrics\")\n",
    "print(\"Validation MSE:\", val_mse)\n",
    "print(\"Validation R^2:\", val_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb403b9-d4b1-4549-8edc-825174dff0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
